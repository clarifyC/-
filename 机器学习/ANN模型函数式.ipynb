{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "info_filename1 = r\"E:\\pycharm files\\housing_pricing_model\\data\\train_data.csv\"\n",
    "info_filename2 = r\"E:\\pycharm files\\housing_pricing_model\\data\\jw.csv\"\n",
    "df_data = pd.read_csv(info_filename1,encoding=\"gbk\")\n",
    "df_jw = pd.read_csv(info_filename2,encoding=\"utf-8\")\n",
    "df_data = df_data.iloc[:,1:53]\n",
    "df = pd.concat([df_data,df_jw],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "i = len(df.columns)\n",
    "df_X = df.iloc[:,1:i]\n",
    "df_y = df.iloc[:,[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scalerXY(df_X,df_y):\n",
    "    scalerX = StandardScaler()\n",
    "    scalery = MinMaxScaler()\n",
    "    \n",
    "    df_scaledX = pd.DataFrame(scalerX.fit_transform(df_X), columns=df_X.columns)\n",
    "    df_scaledy = pd.DataFrame(scalery.fit_transform(df_y), columns=df_y.columns)\n",
    "    \n",
    "    df_scaledy = df_scaledy *0.98+0.01\n",
    "    df_scaledX = df_scaledX*0.98+0.01\n",
    "    \n",
    "    return (scalerX,scalery,df_scaledX,df_scaledy)\n",
    "\n",
    "def scalerX(df_X,scaler_cols):\n",
    "    scalerX = StandardScaler()\n",
    "    idx = df_X.index\n",
    "    # 需要标准化的列\n",
    "    df_scaler_col = df_X[scaler_cols]\n",
    "    \n",
    "    cols = np.array(df_X.columns)\n",
    "    scaler_cols = np.array(scaler_cols)\n",
    "    keep_cols = np.setdiff1d(cols,scaler_cols)\n",
    "    # 不需要标准化的列\n",
    "    df_keep_col = df_X[keep_cols]\n",
    "    \n",
    "    df_scaler_col = pd.DataFrame(scalerX.fit_transform(df_scaler_col), index=idx,columns=df_scaler_col.columns)\n",
    "    \n",
    "    df_scaler = pd.concat([df_scaler_col,df_keep_col],axis=1)\n",
    "    df_scaler = pd.DataFrame(df_scaler,columns=cols)\n",
    "    df_scaler = df_scaler*0.98+0.01\n",
    "    \n",
    "    # print(len(df_X))\n",
    "    # print(len(df_keep_col))\n",
    "    # print(len(df_scaler_col))\n",
    "    # print(len(df_scaler))\n",
    "    return (scalerX,df_scaler)\n",
    "\n",
    "def scalerX_inverse(scalerX,df_scaler,scaler_cols):\n",
    "    idx = df_scaler.index\n",
    "    # 经过标准化的列\n",
    "    df_scaler_col = df_scaler[scaler_cols]\n",
    "    \n",
    "    cols = np.array(df_scaler.columns)\n",
    "    scaler_cols = np.array(scaler_cols)\n",
    "    keep_cols = np.setdiff1d(cols,scaler_cols)\n",
    "    # 没有经过标准化的列\n",
    "    df_keep_col = df_scaler[keep_cols]\n",
    "    \n",
    "    \n",
    "\n",
    "def scalerY(df_y):\n",
    "    scalery = MinMaxScaler()\n",
    "    df_scaledy = pd.DataFrame(scalery.fit_transform(df_y), columns=df_y.columns)\n",
    "    df_scaledy = df_scaledy *0.98+0.01\n",
    "    return (scalery,df_scaledy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# scalerX_train,df_scaler = scalerX(df_X,scaler_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 测试\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def tt_split(X,y,test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=test_size)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.style as style\n",
    "style.use('ggplot')\n",
    "\n",
    "def drawhist(data):\n",
    "    \n",
    "    # data = df_X['挂牌时间']\n",
    "    \n",
    "    # 绘制概率密度图\n",
    "    plt.hist(data, bins=30, density=True, alpha=0.5, color='blue')\n",
    "    \n",
    "    # 添加标题和标签\n",
    "    # plt.title(\"Probability Density Histogram\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    \n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "    \n",
    "# for i in df_X.columns:\n",
    "#     data = df_X[i]\n",
    "#     drawhist(data)\n",
    "#     plt.title(str(i))\n",
    "#     "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import 机器学习.util.ANN as ANN\n",
    "\n",
    "def ANNtrain(X_train,y_train,learning_rate,batch_size,epochs):\n",
    "    input_lay = X_train.shape[1]\n",
    "    output_lay = y_train.shape[1]\n",
    "    print(input_lay,output_lay)\n",
    "    ann = ANN.ANN(layer_number=4,\n",
    "                  layer_neuron=[input_lay,120,110,output_lay],\n",
    "                  learning_rate=learning_rate,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs)\n",
    "    \n",
    "    ann_param = ann.fit(X_train,y_train)\n",
    "    print(f\"loss={ann_param[2]}\")\n",
    "    return (ann,ann_param)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def NN(k,X_train,X_test,y_train,y_test):\n",
    "    # 使用NearestNeighbors找到每个X_test样本的K个最近邻\n",
    "    # k = 4  # 选择K的值\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X_train)\n",
    "    distances, indices = nbrs.kneighbors(X_test)\n",
    "    \n",
    "    y_predict = np.zeros((len(y_test),1))\n",
    "    # 打印每个X_test样本的K个最近邻的索引和距离\n",
    "    for i in range(len(y_test)):\n",
    "        idx = indices[i]\n",
    "        # print(f\"样本{i}的K个最近邻索引：\", indices[i])\n",
    "        # print(f\"样本{i}的K个最近邻距离：\", distances[i])\n",
    "        # print(y_train[idx])\n",
    "        # print(y_train[idx].mean())\n",
    "        # print(y_test[i])\n",
    "        # print(idx)\n",
    "        y_predict[i,0] = y_train.iloc[idx,:].mean()\n",
    "    return y_predict,nbrs\n",
    "    \n",
    "def nbrs_test(nbrs,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    y_predict = np.zeros((len(y_test),1))\n",
    "    distances, indices = nbrs.kneighbors(X_test)\n",
    "    for i in range(len(y_test)):\n",
    "        idx = indices[i]\n",
    "        # print(f\"样本{i}的K个最近邻索引：\", indices[i])\n",
    "        # print(f\"样本{i}的K个最近邻距离：\", distances[i])\n",
    "        # print(y_train[idx])\n",
    "        # print(y_train[idx].mean())\n",
    "        # print(y_test[i])\n",
    "        # print(idx)\n",
    "        y_predict[i,0] = y_train.iloc[idx,:].mean()\n",
    "    \n",
    "    return y_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_X_train, df_X_test, df_y_train, df_y_test= tt_split(df_X,df_y,0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y_predict,nbrs_train = NN\\\n",
    "    (5,df_X_train.loc[:,[\"经度\",'纬度']],df_X_train.loc[:,[\"经度\",'纬度']],df_y_train,df_y_train)\n",
    "\n",
    "# y_error = abs(y_predict-df_y_train.to_numpy().reshape(-1,1))\n",
    "# idx_error = y_error>2000\n",
    "# print()\n",
    "# print(f'错误率：{idx_error.sum()/len(df_y_train)}')\n",
    "\n",
    "df_knnjw = pd.DataFrame(y_predict,columns=['knnjw'],index=df_X_train.index)\n",
    "df_X_train = pd.concat([df_X_train,df_knnjw],axis=1)\n",
    "# df_X_train.drop([\"经度\",\"纬度\"],inplace=True,axis=1)\n",
    "# df_X_train.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "y_predict,nbrs_test = NN(5,df_X_train.loc[:,[\"经度\",'纬度']],df_X_test.loc[:,[\"经度\",'纬度']],df_y_train,df_y_test)\n",
    "df_knnjw_test = pd.DataFrame(y_predict,columns=['knnjw'],index=df_X_test.index)\n",
    "df_X_test = pd.concat([df_X_test,df_knnjw_test],axis=1)\n",
    "# df_X_test.drop([\"经度\",\"纬度\"],inplace=True,axis=1)\n",
    "# df_X_train.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# df_X_test.drop([\"经度\",\"纬度\"],inplace=True,axis=1)\n",
    "# df_X_train.drop([\"经度\",\"纬度\"],inplace=True,axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 标准化\n",
    "# scalerX_train,scalery_train,df_scaledX_train,df_scaledy_train\\\n",
    "#     = scalerXY(df_X_train,df_y_train)\n",
    "# scalerX_test,scalery_test,df_scaledX_test,df_scaledy_test\\\n",
    "#     = scalerXY(df_X_test,df_y_test)\n",
    "scaler_cols = ['建筑面积', '总楼层', '挂牌时间', '物业费用', '建筑年代', '绿  化  率', '容  积  率',\n",
    "        '总楼栋数', '总  户  数', '产权年限', '卧室', '客厅', '卫生间','经度','纬度','knnjw']\n",
    "scalerX_train,df_scaledX_train = scalerX(df_X_train,scaler_cols)\n",
    "scalery_train,df_scaledy_train = scalerY(df_y_train)\n",
    "\n",
    "scalerX_test,df_scaledX_test = scalerX(df_X_test,scaler_cols)\n",
    "scalery_test,df_scaledy_test = scalerY(df_y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2380\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(len(df_X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_train = df_scaledX_train.to_numpy()\n",
    "y_train = df_scaledy_train.to_numpy().reshape(-1,1)\n",
    "\n",
    "X_test = df_scaledX_test.to_numpy()\n",
    "y_test = df_scaledy_test.to_numpy().reshape(-1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2380\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(len(df_scaledX_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "54 1\n",
      "第0次epoch loss=0.044404752362901305\n",
      "第100次epoch loss=0.04440475184325846\n",
      "第200次epoch loss=0.0444047512479687\n",
      "第300次epoch loss=0.04440475055914594\n",
      "第400次epoch loss=0.044404749752770215\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12204/1816842265.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mann\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mann_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mANNtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12204/910722037.py\u001b[0m in \u001b[0;36mANNtrain\u001b[1;34m(X_train, y_train, learning_rate, batch_size, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m                   epochs=epochs)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mann_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"loss={ann_param[2]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mann_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\pycharm files\\housing_pricing_model\\机器学习\\util\\ANN.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mXbatchs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYbatchs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminiBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0mdWlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdBlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbatchs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYbatchs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                 \u001b[0miternum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miternum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\pycharm files\\housing_pricing_model\\机器学习\\util\\ANN.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, X, Y, Wlist, Blist)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mdW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "ann,ann_param = ANNtrain(X_train,y_train,0.17,5,1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "y_hat = ann.transform(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = r\"E:\\pycharm files\\housing_pricing_model\\data\\ann_list.bin\"\n",
    "    # 从二进制文件中读取列表\n",
    "with open(file_name, 'rb') as f:\n",
    "    loaded_list = pickle.load(f)\n",
    "ann1 = loaded_list[0]\n",
    "y_hat = ann1.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "324\n",
      "错误率：0.5445378151260504\n",
      "196\n",
      "错误率：0.32941176470588235\n",
      "116\n",
      "错误率：0.1949579831932773\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def pred_error(y_pred,y_true,scalery_test,abse):\n",
    "    y_true = (y_true-0.01)/0.98\n",
    "    y_pred = (y_pred-0.01)/0.98\n",
    "    df_y_true = scalery_test.inverse_transform(y_true)\n",
    "    df_y_pred = scalery_test.inverse_transform(y_pred)\n",
    "    y_error = df_y_true - df_y_pred\n",
    "    idx_error = abs(y_error)>abse\n",
    "    # print(len(y_true))\n",
    "    print(idx_error.sum())    \n",
    "    acc = idx_error.sum()/len(y_true)\n",
    "    print(f\"错误率：{acc}\")\n",
    "    return acc,idx_error\n",
    "\n",
    "acc2000_ann,idx_error2000_ann = pred_error(y_hat,y_test,scalery_test,2000)\n",
    "acc3000_ann,idx_error3000_ann = pred_error(y_hat,y_test,scalery_test,3000)\n",
    "acc4000_ann,idx_error4000_ann = pred_error(y_hat,y_test,scalery_test,4000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 要持久化的列表\n",
    "def save_ann_param(ann,ann_param,acc):\n",
    "    ann_list = [ann,ann_param,acc]\n",
    "    \n",
    "    # 将列表持久化为二进制文件\n",
    "    file_name = r\"E:\\pycharm files\\housing_pricing_model\\data\\ann_list.bin\"\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(ann_list, f)\n",
    "    print(\"save success\")\n",
    "    # 从二进制文件中读取列表\n",
    "    # with open(file_name, 'rb') as f:\n",
    "    #     loaded_list = pickle.load(f)\n",
    "    \n",
    "    # 输出读取到的列表\n",
    "    # print(loaded_list)\n",
    "# save_ann_param(ann,ann_param,(acc2000_ann,acc3000_ann,acc4000_ann))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "\n",
    "# df_scaledX_test\n",
    "# df_scaledX_test = (df_scaledX_test-0.01)/0.98\n",
    "# scalerX_test.inverse_transform(df_scaledX_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# for i in df_X.columns:\n",
    "#     data = df_error_test[i]\n",
    "#     drawhist(data)\n",
    "#     # plt.title(str(i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "278\n",
      "错误率：0.4672268907563025\n",
      "182\n",
      "错误率：0.3058823529411765\n",
      "123\n",
      "错误率：0.20672268907563024\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个示例数据集\n",
    "\n",
    "# 创建决策树回归模型\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 对新数据进行np.array([[6]])\n",
    "y_pred = model.predict(X_test)\n",
    "# \n",
    "# # 输出预测结果\n",
    "\n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "pred_error(y_pred,y_test,scalery_test,2000)\n",
    "pred_error(y_pred,y_test,scalery_test,3000)\n",
    "pred_error(y_pred,y_test,scalery_test,4000)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\clarifyC\\AppData\\Local\\Temp/ipykernel_12204/30503895.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "338\n",
      "错误率：0.5680672268907563\n",
      "221\n",
      "错误率：0.37142857142857144\n",
      "129\n",
      "错误率：0.21680672268907564\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 创建随机森林回归模型\n",
    "model = RandomForestRegressor(n_estimators=50)\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 对新数据进行预测\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 输出预测结果\n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "acc2000_forest,idx_error2000_forest = pred_error(y_pred,y_test,scalery_test,2000)\n",
    "acc3000_forest,idx_error3000_forest = pred_error(y_pred,y_test,scalery_test,3000)\n",
    "acc4000_forest,idx_error4000_forest = pred_error(y_pred,y_test,scalery_test,4000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "257\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "idx_error2000 = idx_error2000_forest & idx_error2000_ann\n",
    "\n",
    "print(idx_error2000.sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "D:\\Anaconda3_2\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "453\n",
      "错误率：0.761344537815126\n",
      "365\n",
      "错误率：0.6134453781512605\n",
      "284\n",
      "错误率：0.4773109243697479\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(0.4773109243697479,\n array([[ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [False],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [ True],\n        [False],\n        [ True],\n        [False],\n        [False],\n        [ True]]))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "# AdaBoost（Adaptive Boosting）：\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(n_estimators=100)\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "# 输出预测结果\n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "pred_error(y_pred,y_test,scalery_test,2000)\n",
    "pred_error(y_pred,y_test,scalery_test,3000)\n",
    "pred_error(y_pred,y_test,scalery_test,4000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "D:\\Anaconda3_2\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "252\n",
      "错误率：0.4235294117647059\n",
      "168\n",
      "错误率：0.2823529411764706\n",
      "112\n",
      "错误率：0.18823529411764706\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 梯度提升树（Gradient Boosting）\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# 创建梯度提升树分类器\n",
    "model = GradientBoostingRegressor(n_estimators=100)\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "pred_error(y_pred,y_test,scalery_test,2000)\n",
    "pred_error(y_pred,y_test,scalery_test,3000)\n",
    "pred_error(y_pred,y_test,scalery_test,4000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-3829732f",
   "language": "python",
   "display_name": "PyCharm (Datamining)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}